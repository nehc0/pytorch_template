seed: 6

# config for wandb
wandb_cfg:
  use_wandb: True
  project: "IMDb"
  notes: "training details on the process of global rank 0"
  tags: ["IMDb dataset", "TransformerEncoder"]

# config for NLP preprocess
preprocess_nlp_cfg:
  lowercase: True
  rm_punctuation: True
  rm_stopword: False
  lemmatization: True
  min_freq: 3
  max_tokens: 10000

# config for loader
loader_cfg:
  batch_size: 32
  num_workers: 8
  pin_memory: True

# config for model
model_cfg:
  vocab_size: 10000
  embed_dim: 128
  nhead: 2
  dim_feedforward: 512
  num_layers: 2
  num_classes: 2
  dropout: 0.1

# config for optimizer
optimizer_cfg:
  lr: 0.0005
  weight_decay: 0.001

# config for scheduler
scheduler_cfg:
  T_0: 5
  T_mult: 2

# config for train
train_cfg:
  max_epoch: 20
  do_valid: True
  do_test: True
  save_log: True
  save_best: True
  save_checkpoint: True
  resume_checkpoint: False
  # required if `do_valid` is True
  valid_start: 1
  valid_step: 1
  # required if `do_test` is True
  test_start: 1
  test_step: 1
  # required if `save_*` is True
  save_dir: "./imdb_ckpt"
  # required if `save_best` is True
  measure_best: "accuracy"
  measure_mode: "max"
  # required if `save_checkpoint` is True
  checkpoint_latest: True
  checkpoint_list: [10, 15]
  # required if `resume_checkpoint` is True
  resume_path: null
